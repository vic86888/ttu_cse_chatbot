# query.py
from typing import Set

from langchain_ollama import ChatOllama                                    # æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain                        # å®˜æ–¹æ–°å¼æª¢ç´¢éˆ
from langchain.chains.combine_documents import create_stuff_documents_chain

DB_DIR = "storage/chroma"
COLL_NAME = "campus_rag"

def build_chain():
    # 1) æœ¬åœ° LLMï¼ˆOllamaï¼‰ï¼šè«‹å…ˆåœ¨ç³»çµ±ä¸Š `ollama pull llama3.1` æˆ–ä½ æƒ³ç”¨çš„æ¨¡å‹
    llm = ChatOllama(model="cwchang/llama-3-taiwan-8b-instruct:latest", temperature=0)  # ä¹Ÿå¯æ›æˆ "qwen2.5:7b-instruct" ç­‰

    # 2) æç¤ºè©ï¼ˆStuff Documents Chain éœ€è¦ {context} + {input}ï¼‰
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "ä½ æ˜¯å¤§å­¸æ ¡å‹™åŠ©ç†ã€‚åªä¾æ“šæä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œï¼Œ"
         "è‹¥ç„¡æ³•å¾æ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè«‹æ¸…æ¥šèªªæ˜ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡ä½œç­”ã€‚\n\n"
         "{context}"),
        ("human", "{input}")
    ])

    # 3) Stuff chainï¼šæŠŠæª¢ç´¢åˆ°çš„ Documents å¡é€² {context}
    doc_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)

    # 4) é€£æ¥æ—¢æœ‰çš„ Chroma å‘é‡åº« â†’ è½‰æˆ retriever
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        # è‹¥è¦ç”¨ GPUï¼Œæ‰“é–‹ä¸‹ä¸€è¡Œ
        model_kwargs={"device": "cuda"},
    )
    vectordb = Chroma(
        collection_name=COLL_NAME,
        embedding_function=embeddings,
        persist_directory=DB_DIR,
    )
    retriever = vectordb.as_retriever(search_kwargs={"k": 4})

    # 5) å®˜æ–¹æ–°å¼æª¢ç´¢éˆï¼šretriever + doc_chain
    return create_retrieval_chain(retriever, doc_chain)

def pretty_print_sources(context_docs):
    seen: Set[str] = set()
    lines = []
    for d in context_docs:
        src = d.metadata.get("source", "unknown")
        page = d.metadata.get("page")
        key = f"{src}#p{page}" if page is not None else src
        if key in seen:
            continue
        seen.add(key)
        if page is not None:
            lines.append(f"- {src}ï¼ˆç¬¬ {page} é ï¼‰")
        else:
            lines.append(f"- {src}")
    return "\n".join(lines)

if __name__ == "__main__":
    chain = build_chain()
    print("ğŸ’¬ è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼ˆCtrl+C çµæŸï¼‰ï¼š")
    while True:
        try:
            q = input("> ")
            res = chain.invoke({"input": q})   # å›å‚³è‡³å°‘åŒ…å« answer èˆ‡ context
            print("\nğŸ§  ç­”æ¡ˆï¼š\n", res["answer"], "\n", sep="")
            print("ğŸ“š ä¾†æºï¼ˆæª¢ç´¢åˆ°çš„æ–‡ä»¶ç‰‡æ®µï¼‰ï¼š")
            print(pretty_print_sources(res["context"]))
            print("-" * 60)
        except KeyboardInterrupt:
            print("\nå†è¦‹ï¼")
            break
