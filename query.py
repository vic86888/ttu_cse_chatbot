# query.py
from typing import Set
import os

from datetime import datetime
from zoneinfo import ZoneInfo  # æ–°å¢é€™è¡Œ

from operator import itemgetter
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.runnables import RunnableLambda
from langchain_core.documents import Document
from langsmith import traceable
from sentence_transformers import CrossEncoder

DB_DIR = "storage/chroma"
COLL_NAME = "campus_rag"

EVENT_KEYWORDS = [
    "æ–°è", "æ¶ˆæ¯", "news", "æœ€æ–°",
    "æœ€è¿‘", "æ´»å‹•", "èªªæ˜æœƒ", "è¬›åº§", "è«–å£‡", "ç‡ŸéšŠ", "å¾µæ‰"
]

from langchain_core.documents import Document

def rerank_docs(query: str, docs: list[Document], top_n: int) -> list[Document]:
    """ç”¨ cross-encoder å°å€™é¸æ–‡ä»¶é‡æ–°æ’åºï¼Œåªä¿ç•™å‰ top_nã€‚"""
    if not docs:
        return []

    pairs = [[query, d.page_content] for d in docs]
    scores = reranker.predict(pairs)  # é•·åº¦ = len(docs) çš„ numpy array

    scored = sorted(
        zip(docs, scores),
        key=lambda x: float(x[1]),
        reverse=True,
    )

    out: list[Document] = []
    for doc, s in scored[:top_n]:
        md = dict(doc.metadata) if doc.metadata else {}
        md["rerank_score"] = float(s)  # ä¹‹å¾Œ debug å¥½çœ‹ä¸€é»
        out.append(Document(page_content=doc.page_content, metadata=md))

    return out

def make_scored_retriever(vdb, k: int = 10):
    # å…ˆæŠ“æ¯”è¼ƒå¤šï¼Œå†çµ¦ reranker æŒ‘å‰ k
    k_retrieve = max(k * 4, 20)

    def _retrieve(query: str):
        def as_docs(pairs):
            out = []
            for doc, score in pairs:
                md = dict(doc.metadata) if doc.metadata else {}
                md["relevance"] = float(score)
                out.append(Document(page_content=doc.page_content, metadata=md))
            return out

        q = (query or "").lower()
        prefer_news = any(kw in q for kw in EVENT_KEYWORDS)

        docs: list[Document] = []
        if prefer_news:
            news_pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k_retrieve, filter={"content_type": "news"}
            )
            docs.extend(as_docs(news_pairs))

            if len(docs) < k_retrieve:
                more_pairs = vdb.similarity_search_with_relevance_scores(
                    query, k=k_retrieve
                )
                docs.extend(as_docs(more_pairs))

            # å»é‡ï¼ˆsource+article_id æˆ– source+idxï¼‰
            seen = set()
            uniq = []
            for d in docs:
                md = d.metadata or {}
                key = (
                    ("article", md.get("source"), md.get("article_id"))
                    if md.get("article_id")
                    else ("row", md.get("source"), md.get("idx"))
                )
                if key in seen:
                    continue
                seen.add(key)
                uniq.append(d)
            docs = uniq
        else:
            pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k_retrieve
            )
            docs = as_docs(pairs)

        # â­ æœ€é—œéµï¼šç”¨ cross-encoder é‡æ–°æ’åºï¼Œåªä¿ç•™å‰ k å€‹
        docs = rerank_docs(query, docs, top_n=k)
        return docs

    return RunnableLambda(_retrieve).with_config({
        "run_name": "ChromaRetriever+Reranker",
        "tags": ["retriever", "chroma", "with-scores", "rerank"],
        "metadata": {"k": k}
    })

RERANK_MODEL_NAME = "BAAI/bge-reranker-base"
reranker = CrossEncoder(RERANK_MODEL_NAME, device="cuda")  # æ²’ GPU å°±æ‹¿æ‰ device

def build_chain():
    # 1) LLM
    llm = ChatOllama(
#        model="cwchang/llama-3-taiwan-8b-instruct:latest",
        model="qwen3:latest",
        temperature=0,
    ).with_config({
        "run_name": "Ollama-LLM",
        "tags": ["ollama", "tw-8b", "local"],
        "metadata": {"provider": "ollama"},
    })

    # 2) æç¤ºè©
    from langchain_core.prompts import ChatPromptTemplate

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        "ä½ æ˜¯å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äººã€‚\n"
        "ä»Šå¤©æ—¥æœŸæ˜¯ï¼š{today}ï¼Œç¾åœ¨æ™‚é–“æ˜¯ï¼š{now_time}ï¼ˆå°åŒ—æ™‚é–“ï¼‰ã€‚\n"
        "å­¸å¹´ç­‰æ–¼æ°‘åœ‹ç´€å¹´ï¼Œ114å­¸å¹´å°±æ˜¯2025å¹´"
        "ä½ æœƒå¾—åˆ°è·Ÿå•é¡Œç›¸é—œçš„æ–‡ä»¶ï¼Œä½ åªä¾æ“šæä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œï¼Œ"
        "è‹¥ç„¡æ³•å¾æ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè«‹æ¸…æ¥šèªªæ˜ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡ä½œç­”ã€‚\n\n"
        "{context}"),
        ("human", "{input}")
    ])

    # 3) stuff chain
    doc_chain = create_stuff_documents_chain(llm=llm, prompt=prompt).with_config({
        "run_name": "StuffDocumentsChain",
        "tags": ["chain", "stuff"],
    })

    # 4) å‘é‡åº« & æª¢ç´¢å™¨ï¼ˆå«åˆ†æ•¸ï¼‰
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={"device": "cuda"},
        encode_kwargs={"normalize_embeddings": True},  # ğŸ”´ å¾ˆæ¨è–¦åŠ 
    )
    vectordb = Chroma(
        collection_name=COLL_NAME,
        embedding_function=embeddings,
        persist_directory=DB_DIR,
    )

    # âœ¨ é—œéµï¼šå»ºç«‹ scored_retrieverï¼Œç„¶å¾Œç”¨ itemgetter æŠ½å‡º input å­—ä¸²å†é¤µæª¢ç´¢å™¨
    scored_retriever = make_scored_retriever(vectordb, k=10) #ã€€k=5ã€€èª²æœ¬å…§å®¹å¤ªå¤š
    retriever_runnable = itemgetter("input") | scored_retriever  # dict -> str -> [Document]

    # 5) RAG éˆï¼ˆretriever + combine_docsï¼‰
    rag_chain = create_retrieval_chain(retriever_runnable, doc_chain).with_config({
        "run_name": "CampusRAG",
        "tags": ["campus-rag", "cli"],
    })

    # â• åŒ…ä¸€å±¤ï¼šè‡ªå‹•åŠ ä¸Š today
    def inject_today(inputs: dict) -> dict:
        """åœ¨æ¯æ¬¡å‘¼å«æ™‚ï¼Œå‹•æ…‹æ³¨å…¥ä»Šå¤©æ—¥æœŸå­—ä¸²ã€‚"""
        # æ˜ç¢ºä½¿ç”¨å°åŒ—æ™‚é–“ï¼Œè€Œä¸æ˜¯ç³»çµ±é è¨­æ™‚å€
        now = datetime.now(ZoneInfo("Asia/Taipei"))
        today_str = now.strftime("%Y-%m-%d")          # ä¾‹å¦‚ï¼š2025-11-17
        # å¦‚æœä½ æƒ³è¦æ°‘åœ‹æ ¼å¼ï¼Œå¯ä»¥å†å¤šä¸€å€‹ï¼š
        roc_year = now.year - 1911
        today_roc = f"{roc_year}å¹´{now.month}æœˆ{now.day}æ—¥"

        # å¯ä»¥é¸æ“‡ç”¨å“ªä¸€å€‹çµ¦ LLMï¼Œçœ‹ä½ åå¥½ï¼š
        # HH:MM:SSï¼ˆ24 å°æ™‚åˆ¶ï¼‰
        now_time = now.strftime("%H:%M:%S")  # ä¾‹å¦‚ "14:03:27"

        return {
            **inputs,
            "today": today_roc,
            "now_time": now_time,
        }
        # return {**inputs, "today": today_str} # ä»Šå¤©æ—¥æœŸæ˜¯ï¼š(æ°‘åœ‹)114å¹´11æœˆ17æ—¥

    full_chain = RunnableLambda(inject_today) | rag_chain

    return full_chain

def pretty_print_snippets_with_scores(context_docs, max_chars: int = 240):
    seen = set()
    rows = []

    def dedup_key(d):
        md = d.metadata or {}
        src = md.get("source", "unknown")
        if md.get("page") is not None:
            return ("page", src, md.get("page"))
        if md.get("article_id") is not None:
            return ("article", src, md.get("article_id"))
        if md.get("idx") is not None:
            return ("row", src, md.get("idx"))
        return ("src", src)

    for d in context_docs:
        key = dedup_key(d)
        if key in seen:
            continue
        seen.add(key)

        md = d.metadata or {}
        src = md.get("source", "unknown")
        page = md.get("page")
        title = md.get("title")
        chunk = md.get("chunk")
        ctype = md.get("content_type", md.get("type", "unknown"))

        display_idx = len(rows) + 1

        rel = md.get("relevance")
        rr  = md.get("rerank_score")
        rel_str = f"{float(rel):.3f}" if rel is not None else "â€”"
        rr_str  = f"{float(rr):.3f}" if rr is not None else "â€”"

        text = (d.page_content or "").replace("\n", " ").strip()
        snippet = (text[:max_chars] + "â€¦") if len(text) > max_chars else text

        extra = ""
        if page is not None:
            extra = f"ï¼ˆç¬¬ {page} é ï¼‰"
        elif title:
            extra = f"ï¼ˆ{title}ï¼‰"
        elif chunk is not None:
            extra = f"ï¼ˆchunk {chunk}ï¼‰"

        header = f"{display_idx}. [{ctype}] {src}{extra}"
        rows.append(
            f"{header}\n"
            f"   â”” å‘é‡åˆ†æ•¸ï¼š{rel_str}ï½œrerank åˆ†æ•¸ï¼š{rr_str}ï½œç‰‡æ®µï¼š{snippet}"
        )

    return "\n".join(rows)

@traceable(name="CLI-Ask", run_type="chain", metadata={"app": "campus_rag_cli"})
def ask(chain, q: str):
    return chain.invoke({"input": q})

if __name__ == "__main__":
    # éœ€è¦ï¼šexport LANGSMITH_TRACING=true èˆ‡ LANGSMITH_API_KEY
    chain = build_chain()
    print("ğŸ’¬ è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼ˆCtrl+C çµæŸï¼‰ï¼š")
    try:
        while True:
            q = input("> ")
            # q += time()
            res = ask(chain, q)
            print("\nğŸ§  ç­”æ¡ˆï¼š\n", res["answer"], "\n", sep="")
            print("ğŸ“š ä¾†æºã€åˆ†æ•¸èˆ‡ç‰‡æ®µï¼š")
            print(pretty_print_snippets_with_scores(res["context"]))
            print("-" * 60)
    except KeyboardInterrupt:
        print("\nå†è¦‹ï¼")
