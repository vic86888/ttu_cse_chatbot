# query.py
from typing import Set
import os

from operator import itemgetter
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.runnables import RunnableLambda
from langchain_core.documents import Document
from langsmith import traceable

DB_DIR = "storage/chroma"
COLL_NAME = "campus_rag"

def make_scored_retriever(vdb, k: int = 10):
    def _retrieve(query: str):
        def as_docs(pairs):
            out = []
            for doc, score in pairs:
                md = dict(doc.metadata) if doc.metadata else {}
                md["relevance"] = float(score)
                out.append(Document(page_content=doc.page_content, metadata=md))
            return out

        # åˆ¤æ–·æ˜¯å¦åƒåœ¨å•ã€Œæ–°è/æœ€æ–°æ¶ˆæ¯ã€
        q = (query or "").lower()
        prefer_news = any(kw in q for kw in ["æ–°è", "æ¶ˆæ¯", "news", "æœ€æ–°"])

        docs: list[Document] = []
        if prefer_news:
            # LangChain Chroma æ”¯æ´ filter=dict â†’ å°æ‡‰ Chroma where
            news_pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k, filter={"content_type": "news"}
            )
            docs.extend(as_docs(news_pairs))

            if len(docs) < k:
                more_pairs = vdb.similarity_search_with_relevance_scores(query, k=k)
                docs.extend(as_docs(more_pairs))

            # å»é‡ï¼ˆsource+article_id æˆ– source+idxï¼‰
            seen = set()
            uniq = []
            for d in docs:
                md = d.metadata or {}
                key = ("article", md.get("source"), md.get("article_id")) if md.get("article_id") \
                    else ("row", md.get("source"), md.get("idx"))
                if key in seen: 
                    continue
                seen.add(key)
                uniq.append(d)
            docs = uniq[:k]
        else:
            pairs = vdb.similarity_search_with_relevance_scores(query, k=k)
            docs = as_docs(pairs)

        return docs

    return RunnableLambda(_retrieve).with_config({
        "run_name": "ChromaRetriever(scored)",
        "tags": ["retriever", "chroma", "with-scores"],
        "metadata": {"k": k}
    })

def build_chain():
    # 1) LLM
    llm = ChatOllama(
        model="cwchang/llama-3-taiwan-8b-instruct:latest",
        temperature=0,
    ).with_config({
        "run_name": "Ollama-LLM",
        "tags": ["ollama", "tw-8b", "local"],
        "metadata": {"provider": "ollama"},
    })

    # 2) æç¤ºè©
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "ä½ æ˜¯å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äººã€‚ä½ æœƒå¾—åˆ°è·Ÿå•é¡Œç›¸é—œçš„æ–‡ä»¶ï¼Œä½ åªä¾æ“šæä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œï¼Œ"
         "è‹¥ç„¡æ³•å¾æ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè«‹æ¸…æ¥šèªªæ˜ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡ä½œç­”ã€‚\n\n"
         "{context}"),
        ("human", "{input}")
    ]).with_config({
        "run_name": "StuffPrompt",
        "tags": ["prompt", "stuff"],
    })

    # 3) stuff chain
    doc_chain = create_stuff_documents_chain(llm=llm, prompt=prompt).with_config({
        "run_name": "StuffDocumentsChain",
        "tags": ["chain", "stuff"],
    })

    # 4) å‘é‡åº« & æª¢ç´¢å™¨ï¼ˆå«åˆ†æ•¸ï¼‰
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={"device": "cuda"},
    )
    vectordb = Chroma(
        collection_name=COLL_NAME,
        embedding_function=embeddings,
        persist_directory=DB_DIR,
    )

    # âœ¨ é—œéµï¼šå»ºç«‹ scored_retrieverï¼Œç„¶å¾Œç”¨ itemgetter æŠ½å‡º input å­—ä¸²å†é¤µæª¢ç´¢å™¨
    scored_retriever = make_scored_retriever(vectordb, k=20)
    retriever_runnable = itemgetter("input") | scored_retriever  # dict -> str -> [Document]

    # 5) RAG éˆï¼ˆretriever + combine_docsï¼‰
    rag_chain = create_retrieval_chain(retriever_runnable, doc_chain).with_config({
        "run_name": "CampusRAG",
        "tags": ["campus-rag", "cli"],
    })
    return rag_chain

def pretty_print_snippets_with_scores(context_docs, max_chars: int = 240):
    seen = set()
    rows = []

    def dedup_key(d):
        md = d.metadata or {}
        src = md.get("source", "unknown")
        if md.get("page") is not None:
            return ("page", src, md.get("page"))
        if md.get("article_id") is not None:
            return ("article", src, md.get("article_id"))
        if md.get("idx") is not None:
            return ("row", src, md.get("idx"))
        return ("src", src)

    for d in context_docs:
        key = dedup_key(d)
        if key in seen:
            continue
        seen.add(key)

        md = d.metadata or {}
        src = md.get("source", "unknown")
        page = md.get("page")
        title = md.get("title")
        chunk = md.get("chunk")
        ctype = md.get("content_type", md.get("type", "unknown"))

        display_idx = len(rows) + 1

        raw = md.get("relevance")
        try:
            score = float(raw) if raw is not None else None
        except Exception:
            score = None
        score_str = f"{score:.3f}" if score is not None else "â€”"

        text = (d.page_content or "").replace("\n", " ").strip()
        snippet = (text[:max_chars] + "â€¦") if len(text) > max_chars else text

        extra = ""
        if page is not None:
            extra = f"ï¼ˆç¬¬ {page} é ï¼‰"
        elif title:
            extra = f"ï¼ˆ{title}ï¼‰"
        elif chunk is not None:
            extra = f"ï¼ˆchunk {chunk}ï¼‰"

        header = f"{display_idx}. [{ctype}] {src}{extra}"
        rows.append(f"{header}\n   â”” åˆ†æ•¸ï¼š{score_str}ï½œç‰‡æ®µï¼š{snippet}")

    return "\n".join(rows)

@traceable(name="CLI-Ask", run_type="chain", metadata={"app": "campus_rag_cli"})
def ask(chain, q: str):
    return chain.invoke({"input": q})

if __name__ == "__main__":
    # éœ€è¦ï¼šexport LANGSMITH_TRACING=true èˆ‡ LANGSMITH_API_KEY
    chain = build_chain()
    print("ğŸ’¬ è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼ˆCtrl+C çµæŸï¼‰ï¼š")
    try:
        while True:
            q = input("> ")
            res = ask(chain, q)
            print("\nğŸ§  ç­”æ¡ˆï¼š\n", res["answer"], "\n", sep="")
            print("ğŸ“š ä¾†æºã€åˆ†æ•¸èˆ‡ç‰‡æ®µï¼š")
            print(pretty_print_snippets_with_scores(res["context"]))
            print("-" * 60)
    except KeyboardInterrupt:
        print("\nå†è¦‹ï¼")
