# query.py
from typing import Set
import os

from datetime import datetime
from zoneinfo import ZoneInfo  # æ–°å¢é€™è¡Œ

from operator import itemgetter
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.runnables import RunnableLambda
from langchain_core.documents import Document
from langsmith import traceable
from sentence_transformers import CrossEncoder

# Rich å¥—ä»¶ç”¨æ–¼ç¾åŒ–çµ‚ç«¯è¼¸å‡º
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt

console = Console()

DB_DIR = "storage/chroma"
COLL_NAME = "campus_rag"

EVENT_KEYWORDS = [
    "æ–°è", "æ¶ˆæ¯", "news", "æœ€æ–°",
    "æœ€è¿‘", "æ´»å‹•", "èªªæ˜æœƒ", "è¬›åº§", "è«–å£‡", "ç‡ŸéšŠ", "å¾µæ‰"
]

from langchain_core.documents import Document

def rerank_docs(query: str, docs: list[Document], top_n: int) -> list[Document]:
    """ç”¨ cross-encoder å°å€™é¸æ–‡ä»¶é‡æ–°æ’åºï¼Œåªä¿ç•™å‰ top_nã€‚"""
    if not docs:
        return []

    pairs = [[query, d.page_content] for d in docs]
    scores = reranker.predict(pairs)  # é•·åº¦ = len(docs) çš„ numpy array

    scored = sorted(
        zip(docs, scores),
        key=lambda x: float(x[1]),
        reverse=True,
    )

    out: list[Document] = []
    for doc, s in scored[:top_n]:
        md = dict(doc.metadata) if doc.metadata else {}
        md["rerank_score"] = float(s)  # ä¹‹å¾Œ debug å¥½çœ‹ä¸€é»
        out.append(Document(page_content=doc.page_content, metadata=md))

    return out

def make_scored_retriever(vdb, k: int = 10):
    # å…ˆæŠ“æ¯”è¼ƒå¤šï¼Œå†çµ¦ reranker æŒ‘å‰ k
    k_retrieve = max(k * 4, 20)

    def _retrieve(query: str):
        def as_docs(pairs):
            out = []
            for doc, score in pairs:
                md = dict(doc.metadata) if doc.metadata else {}
                md["relevance"] = float(score)
                out.append(Document(page_content=doc.page_content, metadata=md))
            return out

        q = (query or "").lower()
        prefer_news = any(kw in q for kw in EVENT_KEYWORDS)

        docs: list[Document] = []
        if prefer_news:
            news_pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k_retrieve, filter={"content_type": "news"}
            )
            docs.extend(as_docs(news_pairs))

            if len(docs) < k_retrieve:
                more_pairs = vdb.similarity_search_with_relevance_scores(
                    query, k=k_retrieve
                )
                docs.extend(as_docs(more_pairs))

            # å»é‡ï¼ˆsource+article_id æˆ– source+idxï¼‰
            seen = set()
            uniq = []
            for d in docs:
                md = d.metadata or {}
                key = (
                    ("article", md.get("source"), md.get("article_id"))
                    if md.get("article_id")
                    else ("row", md.get("source"), md.get("idx"))
                )
                if key in seen:
                    continue
                seen.add(key)
                uniq.append(d)
            docs = uniq
        else:
            pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k_retrieve
            )
            docs = as_docs(pairs)

        # â­ æœ€é—œéµï¼šç”¨ cross-encoder é‡æ–°æ’åºï¼Œåªä¿ç•™å‰ k å€‹
        docs = rerank_docs(query, docs, top_n=k)
        return docs

    return RunnableLambda(_retrieve).with_config({
        "run_name": "ChromaRetriever+Reranker",
        "tags": ["retriever", "chroma", "with-scores", "rerank"],
        "metadata": {"k": k}
    })

RERANK_MODEL_NAME = "BAAI/bge-reranker-base"
reranker = CrossEncoder(RERANK_MODEL_NAME, device="cpu")

def build_chain():
    # 1) LLM
    llm = ChatOllama(
#        model="cwchang/llama-3-taiwan-8b-instruct:latest",
        model="qwen3:latest",
        temperature=0,
    ).with_config({
        "run_name": "Ollama-LLM",
        "tags": ["ollama", "tw-8b", "local"],
        "metadata": {"provider": "ollama"},
    })

    # 2) æç¤ºè©
    from langchain_core.prompts import ChatPromptTemplate

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        "ä½ æ˜¯å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äººã€‚\n"
        "å­¸å¹´ç­‰æ–¼æ°‘åœ‹ç´€å¹´,114å­¸å¹´å°±æ˜¯2025å¹´ã€‚"
        "ä½ æœƒå¾—åˆ°è·Ÿå•é¡Œç›¸é—œçš„æ–‡ä»¶,ä½ åªä¾æ“šæä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œ,"
        "è‹¥ç„¡æ³•å¾æ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆ,è«‹æ¸…æ¥šèªªæ˜ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡ä½œç­”ã€‚\n\n"
        "{context}"),
        ("human", "{input}")
    ])

    # 3) stuff chain
    doc_chain = create_stuff_documents_chain(llm=llm, prompt=prompt).with_config({
        "run_name": "StuffDocumentsChain",
        "tags": ["chain", "stuff"],
    })

    # 4) å‘é‡åº« & æª¢ç´¢å™¨(å«åˆ†æ•¸)
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        # model_kwargs={"device": "cpu"},
        model_kwargs={"device": "cuda"},
        encode_kwargs={"normalize_embeddings": True},  # ğŸ”´ å¾ˆæ¨è–¦åŠ 
    )
    vectordb = Chroma(
        collection_name=COLL_NAME,
        embedding_function=embeddings,
        persist_directory=DB_DIR,
    )

    # âœ¨ é—œéµï¼šå»ºç«‹ scored_retrieverï¼Œç„¶å¾Œç”¨ itemgetter æŠ½å‡º input å­—ä¸²å†é¤µæª¢ç´¢å™¨
    scored_retriever = make_scored_retriever(vectordb, k=10) #ã€€k=5ã€€èª²æœ¬å…§å®¹å¤ªå¤š
    retriever_runnable = itemgetter("input") | scored_retriever  # dict -> str -> [Document]

    # 5) RAG éˆï¼ˆretriever + combine_docsï¼‰
    rag_chain = create_retrieval_chain(retriever_runnable, doc_chain).with_config({
        "run_name": "CampusRAG",
        "tags": ["campus-rag", "cli"],
    })

    return rag_chain

def pretty_print_snippets_with_scores(context_docs, max_chars: int = 240):
    seen = set()
    rows = []

    def dedup_key(d):
        md = d.metadata or {}
        src = md.get("source", "unknown")
        if md.get("page") is not None:
            return ("page", src, md.get("page"))
        if md.get("article_id") is not None:
            return ("article", src, md.get("article_id"))
        if md.get("idx") is not None:
            return ("row", src, md.get("idx"))
        return ("src", src)

    for d in context_docs:
        key = dedup_key(d)
        if key in seen:
            continue
        seen.add(key)

        md = d.metadata or {}
        src = md.get("source", "unknown")
        page = md.get("page")
        title = md.get("title")
        chunk = md.get("chunk")
        ctype = md.get("content_type", md.get("type", "unknown"))

        display_idx = len(rows) + 1

        rel = md.get("relevance")
        rr  = md.get("rerank_score")
        rel_str = f"{float(rel):.3f}" if rel is not None else "â€”"
        rr_str  = f"{float(rr):.3f}" if rr is not None else "â€”"

        text = (d.page_content or "").replace("\n", " ").strip()
        snippet = (text[:max_chars] + "â€¦") if len(text) > max_chars else text

        extra = ""
        if page is not None:
            extra = f"ï¼ˆç¬¬ {page} é ï¼‰"
        elif title:
            extra = f"ï¼ˆ{title}ï¼‰"
        elif chunk is not None:
            extra = f"ï¼ˆchunk {chunk}ï¼‰"

        header = f"{display_idx}. [{ctype}] {src}{extra}"
        rows.append(
            f"{header}\n"
            f"   â”” å‘é‡åˆ†æ•¸ï¼š{rel_str}ï½œrerank åˆ†æ•¸ï¼š{rr_str}ï½œç‰‡æ®µï¼š{snippet}"
        )

    return "\n".join(rows)

@traceable(name="CLI-Ask", run_type="chain", metadata={"app": "campus_rag_cli"})
def ask(chain, q: str):
    """åŸ·è¡ŒæŸ¥è©¢,è‡ªå‹•åœ¨å•é¡Œå‰åŠ ä¸Šç•¶å‰æ™‚é–“è³‡è¨Š"""
    # å–å¾—å°åŒ—æ™‚é–“
    now = datetime.now(ZoneInfo("Asia/Taipei"))
    roc_year = now.year - 1911
    today_roc = f"{roc_year}å¹´{now.month}æœˆ{now.day}æ—¥"
    # now_time = now.strftime("%H:%M:%S")
    
    # å°‡æ™‚é–“è³‡è¨Šé™„åŠ åˆ°å•é¡Œå‰é¢
    # timestamped_q = f"[ç•¶å‰æ™‚é–“: {today_roc} {now_time}] {q}"
    timestamped_q = f"[ç•¶å‰æ™‚é–“: {today_roc} ] {q}"
    
    return chain.invoke({"input": timestamped_q})

if __name__ == "__main__":
    # éœ€è¦ï¼šexport LANGSMITH_TRACING=true èˆ‡ LANGSMITH_API_KEY
    chain = build_chain()
    
    # ä½¿ç”¨ rich é¡¯ç¤ºæ­¡è¿è¨Šæ¯
    console.print(Panel.fit(
        "ğŸ’¬ å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äºº\nè¼¸å…¥å•é¡Œé–‹å§‹å°è©±ï¼ŒæŒ‰ Ctrl+C çµæŸ",
        title="æ­¡è¿",
        border_style="cyan"
    ))
    
    try:
        while True:
            # ä½¿ç”¨ rich çš„ Prompt å–ä»£ input
            q = Prompt.ask("\n[bold cyan]â“ ä½ çš„å•é¡Œ[/bold cyan]")
            
            if not q.strip():
                continue
            
            # åŸ·è¡ŒæŸ¥è©¢
            res = ask(chain, q)
            
            # ä½¿ç”¨ rich Markdown æ¸²æŸ“ç­”æ¡ˆ
            console.print("\n[bold green]ğŸ§  ç­”æ¡ˆï¼š[/bold green]")
            console.print(Panel(
                Markdown(res["answer"]),
                border_style="green",
                padding=(1, 2)
            ))
            
            # é¡¯ç¤ºä¾†æºè³‡è¨Š
            console.print("\n[bold yellow]ğŸ“š åƒè€ƒä¾†æºï¼š[/bold yellow]")
            sources_text = pretty_print_snippets_with_scores(res["context"])
            console.print(sources_text)
            
            console.print("[dim]" + "â”€" * 80 + "[/dim]\n")
            
    except KeyboardInterrupt:
        console.print("\n[bold blue]ğŸ‘‹ å†è¦‹ï¼[/bold blue]")
