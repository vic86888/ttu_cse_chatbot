# query.py
from typing import Set
import os
import re

from datetime import datetime
from zoneinfo import ZoneInfo  # æ–°å¢é€™è¡Œ

from operator import itemgetter
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.runnables import RunnableLambda
from langchain_core.documents import Document
from langsmith import traceable
from sentence_transformers import CrossEncoder

# Rich å¥—ä»¶ç”¨æ–¼ç¾åŒ–çµ‚ç«¯è¼¸å‡º
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Prompt

Prompt.prompt_suffix = ""  # æˆ– " " ä¹‹é¡çš„ï¼Œé¿å…é è¨­çš„å†’è™Ÿ

console = Console()

DB_DIR = "storage/chroma"
COLL_NAME = "campus_rag"

# ä½ åŸæœ¬çš„é—œéµå­—
EVENT_KEYWORDS = ["æ–°è","æ¶ˆæ¯","news","æœ€æ–°","æœ€è¿‘","æ´»å‹•","èªªæ˜æœƒ","è¬›åº§","è«–å£‡","ç‡ŸéšŠ","å¾µæ‰","è¡Œäº‹æ›†"]

# æ™‚é–“çª—åƒæ•¸ï¼ˆè‡ªè¡Œèª¿æ•´ï¼‰
NEWS_LOOKBACK_DAYS = 120   # æ–°èï¼šåªæŠ“éå» N å¤©ï¼ˆå«ä»Šå¤©ï¼‰
CAL_PAST_DAYS      = 60    # è¡Œäº‹æ›†ï¼šæŠ“éå» N å¤©
CAL_FUTURE_DAYS    = 180   # è¡Œäº‹æ›†ï¼šæŠ“æœªä¾† N å¤©

from langchain_core.documents import Document

def rerank_docs(query: str, docs: list[Document], top_n: int) -> list[Document]:
    """ç”¨ cross-encoder å°å€™é¸æ–‡ä»¶é‡æ–°æ’åºï¼Œåªä¿ç•™å‰ top_nã€‚"""
    if not docs:
        return []

    pairs = [[query, d.page_content] for d in docs]
    scores = reranker.predict(pairs)  # é•·åº¦ = len(docs) çš„ numpy array

    scored = sorted(
        zip(docs, scores),
        key=lambda x: float(x[1]),
        reverse=True,
    )

    out: list[Document] = []
    for doc, s in scored[:top_n]:
        md = dict(doc.metadata) if doc.metadata else {}
        md["rerank_score"] = float(s)  # ä¹‹å¾Œ debug å¥½çœ‹ä¸€é»
        out.append(Document(page_content=doc.page_content, metadata=md))

    return out

def make_scored_retriever(vdb, k: int = 10):
    k_retrieve = max(k * 4, 100)

    def _retrieve(query: str):
        def as_docs(pairs):
            out = []
            for doc, score in pairs:
                md = dict(doc.metadata) if doc.metadata else {}
                md["relevance"] = float(score)
                out.append(Document(page_content=doc.page_content, metadata=md))
            return out

        q_lower = (query or "").lower()
        prefer_news = any(kw in q_lower for kw in EVENT_KEYWORDS)

        docs: list[Document] = []

        if prefer_news:
            now_ts = int(datetime.now(ZoneInfo("Asia/Taipei")).timestamp())

            # --- 1) æ–°èï¼šåªæŠ“éå» NEWS_LOOKBACK_DAYS å¤© ---
            news_cutoff = now_ts - NEWS_LOOKBACK_DAYS * 24 * 3600
            news_pairs = vdb.similarity_search_with_relevance_scores(
                query,
                k=k_retrieve,
                filter={
                    "$and": [
                        {"content_type": "news"},
                        {"published_at_ts": {"$gte": news_cutoff}}
                    ]
                }
            )
            docs.extend(as_docs(news_pairs))

            # --- 2) è¡Œäº‹æ›†ï¼šæŠ“éå» CAL_PAST_DAYS å¤© + æœªä¾† CAL_FUTURE_DAYS å¤© ---
            cal_start = now_ts - CAL_PAST_DAYS * 24 * 3600
            cal_end   = now_ts + CAL_FUTURE_DAYS * 24 * 3600

            cal_pairs = vdb.similarity_search_with_relevance_scores(
                query,
                k=k_retrieve,
                filter={
                    "$and": [
                        {"content_type": "calendar"},          # ä½ æ–°å¢çš„ event docs
                        {"event_date_ts": {"$gte": cal_start}},
                        {"event_date_ts": {"$lte": cal_end}},
                    ]
                }
            )
            docs.extend(as_docs(cal_pairs))

            # ï¼ˆå¯é¸ï¼‰Fallbackï¼šå¦‚æœä½ é‚„æ²’åŠ  calendar_events_to_documentsï¼Œ
            # åªæœƒæœ‰ calendar_month chunkï¼Œé€™è£¡è£œæŠ“ä¸€é»é¿å…å®Œå…¨ç©º
            if not cal_pairs:
                cal_month_pairs = vdb.similarity_search_with_relevance_scores(
                    query,
                    k=min(20, k_retrieve),
                    filter={"content_type": "calendar_month"}
                )
                docs.extend(as_docs(cal_month_pairs))

            # --- 3) ä¸å¤ å†è£œä¸€èˆ¬å€™é¸ ---
            if len(docs) < k_retrieve:
                more_pairs = vdb.similarity_search_with_relevance_scores(
                    query, k=k_retrieve
                )
                docs.extend(as_docs(more_pairs))

            # --- 4) å»é‡ ---
            seen = set()
            uniq = []
            for d in docs:
                md = d.metadata or {}
                key = (
                    ("page", md.get("source"), md.get("page"))
                    if md.get("page") is not None
                    else ("article", md.get("source"), md.get("article_id"))
                    if md.get("article_id")
                    else ("row", md.get("source"), md.get("idx"))
                )
                if key in seen:
                    continue
                seen.add(key)
                uniq.append(d)
            docs = uniq

        else:
            pairs = vdb.similarity_search_with_relevance_scores(
                query, k=k_retrieve
            )
            docs = as_docs(pairs)

        # --- 5) cross-encoder rerankï¼ˆèªæ„ï¼‰---
        docs = rerank_docs(query, docs, top_n=k)

        # --- 6) prefer_news æ™‚åšã€Œæ™‚é–“å°å‘ final sortã€---
        if prefer_news:
            now_ts = int(datetime.now(ZoneInfo("Asia/Taipei")).timestamp())

            def time_key(d):
                md = d.metadata or {}
                ts = md.get("published_at_ts") or md.get("event_date_ts") or 0
                rr = md.get("rerank_score") or 0.0

                # è®“ã€Œé›¢ç¾åœ¨æœ€è¿‘ã€çš„æ’å‰é¢ï¼Œä¸”æœªä¾†æ´»å‹•å„ªå…ˆæ–¼éå»æ´»å‹•
                future_flag = 0 if ts >= now_ts else 1
                delta = abs(int(ts) - now_ts)
                return (future_flag, delta, -float(rr))

            docs = sorted(docs, key=time_key)

        return docs

    return RunnableLambda(_retrieve).with_config({
        "run_name": "ChromaRetriever+Reranker",
        "tags": ["retriever", "chroma", "with-scores", "rerank"],
        "metadata": {"k": k}
    })

RERANK_MODEL_NAME = "BAAI/bge-reranker-base"
reranker = CrossEncoder(RERANK_MODEL_NAME, device="cuda")  # æˆ– "cpu"

def build_chain():
    # 1) LLM
    llm = ChatOllama(
        # model="cwchang/llama-3-taiwan-8b-instruct:latest",
        model="qwen3:latest",
        temperature=0,
    ).with_config({
        "run_name": "Ollama-LLM",
        "tags": ["ollama", "tw-8b", "local"],
        "metadata": {"provider": "ollama"},
    })

    # 2) æç¤ºè©
    from langchain_core.prompts import ChatPromptTemplate

    # åœ¨ build_chain å‡½å¼å…§ä¿®æ”¹ prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system",
        "ç¾åœ¨æ™‚é–“ï¼š{now}\n\n"
        "ç›®å‰å­¸æœŸï¼š{acad_term}\n\n"
        "ä½ æ˜¯å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äººã€‚è«‹æ ¹æ“šç³»çµ±æä¾›çš„è³‡è¨Šï¼ˆå¦‚ç¾åœ¨æ™‚é–“ã€ç›®å‰å­¸æœŸï¼‰ä»¥åŠèˆ‡å•é¡Œç›¸é—œçš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œã€‚"
        "å›ç­”çµå°¾éœ€é™„ä¸Šåƒè€ƒç¶²å€ï¼Œè‹¥æ²’æœ‰å‰‡é™„ä¸Šä¾†æºæ–‡ä»¶"
        "è‹¥ç„¡æ³•å¾ç³»çµ±æä¾›çš„è³‡è¨Šï¼ˆå¦‚ç¾åœ¨æ™‚é–“ã€ç›®å‰å­¸æœŸï¼‰ä»¥åŠæ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè«‹æ¸…æ¥šèªªæ˜ã€‚è«‹ä»¥ç¹é«”ä¸­æ–‡ä½œç­”ã€‚\n\n"
        "{context}"
        ),
        ("human", "{input}")
    ]).with_config({
        "tags": ["chain", "stuff"],
    })

    # 3) stuff chain
    doc_chain = create_stuff_documents_chain(llm=llm, prompt=prompt).with_config({
        "run_name": "StuffDocumentsChain",
        "tags": ["chain", "stuff"],
    })

    # 4) å‘é‡åº« & æª¢ç´¢å™¨(å«åˆ†æ•¸)
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        # model_kwargs={"device": "cpu"},
        model_kwargs={"device": "cuda"},
        encode_kwargs={"normalize_embeddings": True},  # ğŸ”´ å¾ˆæ¨è–¦åŠ 
    )
    vectordb = Chroma(
        collection_name=COLL_NAME,
        embedding_function=embeddings,
        persist_directory=DB_DIR,
    )

    # âœ¨ é—œéµï¼šå»ºç«‹ scored_retrieverï¼Œç„¶å¾Œç”¨ itemgetter æŠ½å‡º input å­—ä¸²å†é¤µæª¢ç´¢å™¨
    scored_retriever = make_scored_retriever(vectordb, k=10) #ã€€k=5ã€€èª²æœ¬å…§å®¹å¤ªå¤š
    retriever_runnable = itemgetter("input") | scored_retriever  # dict -> str -> [Document]

    # 5) RAG éˆï¼ˆretriever + combine_docsï¼‰
    rag_chain = create_retrieval_chain(retriever_runnable, doc_chain).with_config({
        "run_name": "CampusRAG",
        "tags": ["campus-rag", "cli"],
    })

    return rag_chain

def pretty_print_snippets_with_scores(context_docs, max_chars: int = 240):
    seen = set()
    rows = []

    def dedup_key(d):
        md = d.metadata or {}
        src = md.get("source", "unknown")
        if md.get("page") is not None:
            return ("page", src, md.get("page"))
        if md.get("article_id") is not None:
            return ("article", src, md.get("article_id"))
        if md.get("idx") is not None:
            return ("row", src, md.get("idx"))
        return ("src", src)

    for d in context_docs:
        key = dedup_key(d)
        if key in seen:
            continue
        seen.add(key)

        md = d.metadata or {}
        src = md.get("source", "unknown")
        page = md.get("page")
        title = md.get("title")
        chunk = md.get("chunk")
        ctype = md.get("content_type", md.get("type", "unknown"))

        display_idx = len(rows) + 1

        rel = md.get("relevance")
        rr  = md.get("rerank_score")
        rel_str = f"{float(rel):.3f}" if rel is not None else "â€”"
        rr_str  = f"{float(rr):.3f}" if rr is not None else "â€”"

        text = (d.page_content or "").replace("\n", " ").strip()
        snippet = (text[:max_chars] + "â€¦") if len(text) > max_chars else text

        extra = ""
        if page is not None:
            extra = f"ï¼ˆç¬¬ {page} é ï¼‰"
        elif title:
            extra = f"ï¼ˆ{title}ï¼‰"
        elif chunk is not None:
            extra = f"ï¼ˆchunk {chunk}ï¼‰"

        header = f"{display_idx}. [{ctype}] {src}{extra}"
        rows.append(
            f"{header}\n"
            f"   â”” å‘é‡åˆ†æ•¸ï¼š{rel_str}ï½œrerank åˆ†æ•¸ï¼š{rr_str}ï½œç‰‡æ®µï¼š{snippet}"
        )

    return "\n".join(rows)

@traceable(name="CLI-Ask", run_type="chain", metadata={"app": "campus_rag_cli"})
def ask(chain, q: str):
    now = datetime.now(ZoneInfo("Asia/Taipei"))
    roc_year = now.year - 1911

    m, d = now.month, now.day

    # ä¾è¦å®šï¼š8/1 é–‹å§‹æ–°å­¸å¹´ï¼›2/1 é–‹å§‹ç¬¬äºŒå­¸æœŸ
    if (m, d) >= (8, 1):
        acad_year = roc_year
        sem = "ç¬¬ä¸€å­¸æœŸ"
    elif (m, d) >= (2, 1):
        acad_year = roc_year - 1
        sem = "ç¬¬äºŒå­¸æœŸ"
    else:
        acad_year = roc_year - 1
        sem = "ç¬¬ä¸€å­¸æœŸ"

    acad_term = f"{acad_year}å­¸å¹´{sem}"

    now_str = f"æ°‘åœ‹{roc_year}å¹´{m}æœˆ{d}æ—¥ {now.strftime('%H:%M')}"

    # âœ… å¤šå‚³ acad_term çµ¦ prompt
    return chain.invoke({
        "input": q,
        "now": now_str,
        "acad_term": acad_term
    })

if __name__ == "__main__":
    # éœ€è¦ï¼šexport LANGSMITH_TRACING=true èˆ‡ LANGSMITH_API_KEY
    chain = build_chain()
    
    # ä½¿ç”¨ rich é¡¯ç¤ºæ­¡è¿è¨Šæ¯
    console.print(Panel.fit(
        "ğŸ’¬ å¤§åŒå¤§å­¸è³‡å·¥ç³»å•ç­”æ©Ÿå™¨äºº\nè¼¸å…¥å•é¡Œé–‹å§‹å°è©±ï¼ŒæŒ‰ Ctrl+C çµæŸ",
        title="æ­¡è¿",
        border_style="cyan"
    ))
    
    try:
        while True:
            # ä½¿ç”¨ rich çš„ Prompt å–ä»£ input
            console.print("[bold cyan]â“ ä½ çš„å•é¡Œ[/bold cyan]")
            q = Prompt.ask("")  # ç©ºæç¤ºï¼Œè®“ä½¿ç”¨è€…å¾ç©ºæ¬„è¼¸å…¥
            
            if not q.strip():
                continue
            
            # åŸ·è¡ŒæŸ¥è©¢
            res = ask(chain, q)            
            raw = res["answer"]
            # --- ä¿®æ”¹é–‹å§‹ï¼šä½¿ç”¨ Regex è§£æ XML ---
            thinking = ""
            answer = raw

            # 1. å˜—è©¦æå– <think> å€å¡Š
            think_match = re.search(r"<think>(.*?)</think>", raw, re.DOTALL)
            if think_match:
                thinking = think_match.group(1).strip()

            # 2. å˜—è©¦æå– <answer> å€å¡Š
            answer_match = re.search(r"<answer>(.*?)</answer>", raw, re.DOTALL)
            if answer_match:
                answer = answer_match.group(1).strip()
            else:
                # å¦‚æœæ‰¾ä¸åˆ° <answer> æ¨™ç±¤ï¼Œå¯èƒ½æ¨¡å‹æ²’è·Ÿéš¨æ ¼å¼
                # ç‚ºäº†ä¿éšªï¼Œå¦‚æœæ‰¾åˆ°äº† <think>ï¼Œå°±æŠŠå‰©ä¸‹çš„ç•¶ä½œ answer
                # æˆ–è€…ç›´æ¥é¡¯ç¤ºåŸå§‹æ–‡å­—
                if think_match:
                    # æŠŠ raw ä¸­çš„ <think>...</think> ç§»é™¤ï¼Œå‰©ä¸‹çš„ç•¶ä½œå›ç­”
                    answer = raw.replace(think_match.group(0), "").strip()
            # --- ä¿®æ”¹çµæŸ ---

            # å°æ€è€ƒ
            if thinking:
                console.print("\n[bold purple]ğŸ” æ€è€ƒéç¨‹ï¼š[/bold purple]")
                console.print(Panel(
                Markdown(thinking),
                border_style="purple",
                padding=(1,2)
            ))
            
            # å°æœ€çµ‚å›ç­” (å¦‚æœæœ‰è§£æå¤±æ•—ï¼Œanswer æœƒæ˜¯åŸå§‹å…¨æ–‡ï¼Œè‡³å°‘ä¸æœƒå ±éŒ¯)
            console.print("\n[bold green]âœ… æœ€çµ‚å›ç­”ï¼š[/bold green]")
            console.print(Panel(
                Markdown(answer),
                border_style="green",
                padding=(1,2)
            ))
            
            # é¡¯ç¤ºä¾†æºè³‡è¨Š
            console.print("\n[bold yellow]ğŸ“š åƒè€ƒä¾†æºï¼š[/bold yellow]")
            sources_text = pretty_print_snippets_with_scores(res["context"])
            console.print(sources_text)
            
            console.print("[dim]" + "â”€" * 80 + "[/dim]\n")
            
    except KeyboardInterrupt:
        console.print("\n[bold blue]ğŸ‘‹ å†è¦‹ï¼[/bold blue]")
