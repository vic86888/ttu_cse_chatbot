# eval_rag.py
import json
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo

from datasets import Dataset
from ragas import evaluate
from ragas.run_config import RunConfig
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_recall,
    context_precision,
    answer_correctness,   # â† æ–°åŠ é€™å€‹
)

run_config = RunConfig(
    timeout=600,    # å–®å€‹æ‰“åˆ†å·¥ä½œçš„è¶…æ™‚ä¸Šé™ï¼Œå…ˆè©¦ 180 ç§’
    max_workers=1,  # æœ€å¤šå…©å€‹è©•åˆ†ä»»å‹™åŒæ™‚è·‘ï¼Œé¿å…æŠŠ Ollama å£“çˆ†
    max_retries=3,  # è¶…æ™‚æ™‚æœ€å¤šé‡è©¦ä¸€æ¬¡
)


from query import build_chain, extract_clean_query
from langchain_huggingface import HuggingFaceEmbeddings

# ğŸŸ¢ è«‹åŠ å…¥é€™ä¸€è¡Œï¼š
from langchain_openai import ChatOpenAI

EVAL_QA_PATH = Path("eval/eval_qa_18 copy 2.jsonl")  # ä½ å¯ä»¥è‡ªå·±èª¿æ•´è·¯å¾‘

def load_eval_qa(path: Path):
    items = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            items.append(json.loads(line))
    return items

def run_rag_for_eval(chains, question: str, now_str: str, acad_term: str):
    """è·Ÿ query.ask å¾ˆåƒï¼Œä½†ä¸å°æ±è¥¿ï¼Œä¹¾æ·¨å›å‚³çµæœã€‚"""
    rewrite_chain = chains["rewrite"]
    rag_chain = chains["rag"]

    # 1) æ™‚é–“ query rewriter
    try:
        raw_rewrite = rewrite_chain.invoke({"query": question, "now": now_str})
        rewritten_q = extract_clean_query(raw_rewrite)
    except Exception:
        rewritten_q = question

    if not rewritten_q:
        rewritten_q = question

    # 2) RAG QA
    res = rag_chain.invoke({
        "input": rewritten_q,
        "now": now_str,
        "acad_term": acad_term,
        "original_query": question,
        "rewritten_query": rewritten_q,
    })

    answer = res["answer"]
    context_docs = res["context"]

    return {
        "original_question": question,
        "rewritten_question": rewritten_q,
        "answer": answer,
        "contexts": [d.page_content for d in context_docs],
        "raw_context_docs": context_docs,  # å¦‚æœä½ æ—¥å¾Œè¦çœ‹ metadata
    }

def get_now_and_term():
    now = datetime.now(ZoneInfo("Asia/Taipei"))
    roc_year = now.year - 1911
    m, d = now.month, now.day

    if (m, d) >= (8, 1):
        acad_year = roc_year
        sem = "ç¬¬ä¸€å­¸æœŸ"
    elif (m, d) >= (2, 1):
        acad_year = roc_year - 1
        sem = "ç¬¬äºŒå­¸æœŸ"
    else:
        acad_year = roc_year - 1
        sem = "ç¬¬ä¸€å­¸æœŸ"

    acad_term = f"{acad_year}å­¸å¹´{sem}"
    now_str = f"æ°‘åœ‹{roc_year}å¹´{m}æœˆ{d}æ—¥ {now.strftime('%H:%M')}"
    return now_str, acad_term

def main():
    eval_items = load_eval_qa(EVAL_QA_PATH)
    print(f"è¼‰å…¥ {len(eval_items)} é¡Œæ¸¬è©¦é¡Œç›®")

    # å»º chainï¼ˆæœƒé€£åŒ embeddings, Chroma ä¸€èµ·è¼‰ï¼‰
    chains = build_chain()
    now_str, acad_term = get_now_and_term()

    rows = []
    for item in eval_items:
        q = item["question"]
        gt = item["expected_answer"]

        out = run_rag_for_eval(chains, q, now_str, acad_term)

        rows.append({
            "question": q,
            "answer": out["answer"],
            "contexts": out["contexts"],
            "ground_truth": gt,
            "original_question": out["original_question"],
            "rewritten_question": out["rewritten_question"],
            "category": item.get("category", ""),
        })

    # è½‰æˆ HuggingFace Datasetï¼Œçµ¦ ragas ç”¨
    ds = Dataset.from_list([
        {
            "question": r["question"],
            "answer": r["answer"],
            "contexts": r["contexts"],
            "ground_truth": r["ground_truth"],
        }
        for r in rows
    ])

    # ç”¨å“ªå€‹ LLM ç•¶è©•å¯©ï¼Ÿä½ å¯ä»¥å…ˆç”¨åŒä¸€å€‹ Qwen3ï¼Œä¹Ÿå¯ä»¥æ›ä¸€å€‹æ›´ç©©å®šçš„é›²ç«¯æ¨¡å‹ã€‚

    # ä½¿ç”¨ GPT-4o-mini (æ¨è–¦ï¼Œä¾¿å®œåˆå¿«)
    judge_llm = ChatOpenAI(
        model="gpt-4o-mini", 
        temperature=0,
        # openai_api_key="sk-...", # å»ºè­°è®€å–ç’°å¢ƒè®Šæ•¸ï¼Œä¸è¦å¯«æ­»åœ¨ code è£¡
    )

    # 2) è©•å¯©ç”¨ embeddingsï¼šç›´æ¥ç”¨ BGE-M3ï¼ˆè¦ GPU é‚„æ˜¯ CPU ä½ è‡ªå·±é¸ï¼‰
    ragas_embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        # å¦‚æœ GPU é‚„æœ‰ç©ºé–“ï¼Œå°±ï¼š
        model_kwargs={"device": "cuda"},
        encode_kwargs={"normalize_embeddings": True},
    )

    # é–‹å§‹è©•æ¸¬
    result = evaluate(
        dataset=ds,
        metrics=[faithfulness, answer_relevancy, context_recall, context_precision, answer_correctness], # é€™æ¨£å°±æœƒå¤šå‡ºä¸€æ ¼
        llm=judge_llm,          # âœ… é›²ç«¯è£åˆ¤ (è² è²¬æ‰“åˆ†é‚è¼¯)
        embeddings=ragas_embeddings, # âœ… æœ¬åœ° Embeddings (è² è²¬ç®—ç›¸ä¼¼åº¦)
        run_config=run_config,
    )

    print("=== RAG è©•ä¼°çµæœ ===")

    # 1) å…ˆè½‰æˆ DataFrame
    df = result.to_pandas()

    # ä½ ç›®å‰ç”¨çš„å››å€‹æŒ‡æ¨™åç¨±
    metric_cols = ["faithfulness", "answer_relevancy", "context_recall", "context_precision", "answer_correctness"]

    # 2) é¡¯ç¤ºæ¯ä¸€é¡Œçš„åˆ†æ•¸
    print("\n=== æ¯é¡Œåˆ†æ•¸ ===")
    for i, row in df.iterrows():
        q = row.get("question", f"Q{i}")
        scores = "ï½œ".join(
            f"{m}={row[m]:.3f}" if m in row and row[m] == row[m] else f"{m}=NaN"
            for m in metric_cols
        )
        print(f"- {q} -> {scores}")

    # 3) é¡¯ç¤ºå¹³å‡åˆ†æ•¸
    print("\n=== å¹³å‡åˆ†æ•¸ ===")
    for m in metric_cols:
        if m in df.columns:
            mean_val = df[m].mean()
            print(f"{m}: {mean_val:.3f}")

    # â­ æ–°å¢å€å¡Šï¼šæŠŠ answer_relevancy ç‚º 0 çš„å•ç­”å°å‡ºä¾†
    if "answer_relevancy" in df.columns:
        # å…ˆæ‰¾å‡ºå“ªå¹¾å€‹ index çš„ answer_relevancy = 0
        zero_idx_list = df.index[df["answer_relevancy"] == 0].tolist()

        if zero_idx_list:
            print("\n=== answer_relevancy = 0 çš„é¡Œç›®ï¼ˆå»ºè­°å„ªå…ˆæ’æŸ¥ï¼‰=== ")
            for idx in zero_idx_list:
                # ç”¨ idx å›é ­æ‹¿ä½ ç•¶åˆå­˜å¥½çš„ rows è£¡çš„å…§å®¹
                qa = rows[idx]   # rows æ˜¯ä½ ä¸Šé¢è‡ªå·±çµ„çš„ list

                print("\n----------------------------------------")
                print(f"[ç´¢å¼•] {idx}")
                print(f"[å•é¡Œ] {qa.get('question', '')}")
                print(f"[æ¨¡å‹å›ç­”]\n{qa.get('answer', '')}")
                print(f"[æ¨™æº–ç­”æ¡ˆ ground_truth]\n{qa.get('ground_truth', '')}")
                # å¦‚æœæƒ³é †ä¾¿çœ‹ä¸€ä¸‹è©²é¡Œçš„åˆ†æ•¸ï¼Œä¹Ÿå¯ä»¥å°ï¼š
                print(f"[answer_relevancy åˆ†æ•¸] {df.loc[idx, 'answer_relevancy']:.3f}")
        else:
            print("\nï¼ˆæ²’æœ‰ answer_relevancy = 0 çš„é¡Œç›®ï¼‰")

if __name__ == "__main__":
    main()
